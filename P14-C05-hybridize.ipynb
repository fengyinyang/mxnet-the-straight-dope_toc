{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Faster, and portable through hybridizing\n",
    "\n",
    "The tutorials we saw so far adopt the *imperative*, or define-by-run, programming paradigm. This is how we write Python programs. Another commonly used programming paradigm by deep learning frameworks is the *symbolic*, or define-then-run, programming. It consists of three steps:\n",
    "\n",
    "- define the workloads, such as creating the neural network\n",
    "- compile the program into a front-end language, e.g. Python, independent format\n",
    "- feed with data to run\n",
    "\n",
    "This compilation step may optimize the program to be more efficient to run, and also the resulting language-independent format make the program portable to various front-end languages. \n",
    "\n",
    "`gluon` provides a *hybrid* mechanism to seamless combine both declarative programming and imperative programming. Users can freely switch between them to enjoy the advantages of both paradigms. \n",
    "\n",
    "## HybridSequential\n",
    "\n",
    "We already learned how to use `Sequential` to stack the layers. Now, we have `HybridSequential` that constructs a hybrid network. Its usage is similar to `Sequential`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== net(x) ===\n",
      "[[ 0.16526189 -0.14005633]]\n",
      "<NDArray 1x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "def get_net():\n",
    "    # construct a MLP\n",
    "    net = nn.HybridSequential()\n",
    "    with net.name_scope():\n",
    "        net.add(nn.Dense(256, activation=\"relu\"))\n",
    "        net.add(nn.Dense(128, activation=\"relu\"))\n",
    "        net.add(nn.Dense(2))\n",
    "    # initialize the parameters\n",
    "    net.collect_params().initialize()\n",
    "    return net\n",
    "\n",
    "# forward\n",
    "x = nd.random_normal(shape=(1, 512))\n",
    "net = get_net()\n",
    "print('=== net(x) ==={}'.format(net(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network constructed by `HybridSequential` can be called `hybridize` to hint `gluon` to compile it through the symbolic way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== net(x) ===\n",
      "[[ 0.16526189 -0.14005633]]\n",
      "<NDArray 1x2 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "net.hybridize()\n",
    "print('=== net(x) ==={}'.format(net(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "We compare the performance between before hybridizing and after hybridizing by forwarding 1000 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before hybridizing: 0.4522 sec\n",
      "After hybridizing: 0.3320 sec\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "def bench(net, x):\n",
    "    start = time()\n",
    "    for i in range(1000):\n",
    "        y = net(x)\n",
    "    y.wait_to_read()\n",
    "    return time() - start\n",
    "        \n",
    "net = get_net()\n",
    "print('Before hybridizing: %.4f sec'%(bench(net, x)))\n",
    "net.hybridize()\n",
    "print('After hybridizing: %.4f sec'%(bench(net, x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can been seen, there is a significant speedup after hybridizing.\n",
    "\n",
    "## Get the symbolic program\n",
    "\n",
    "Previously, we feed `net` with data `x`, and then `net(x)` returned the forward results. Now if we feed it with a symbolic data placeholder, then the corresponding symbolic program will be returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== input data holder ===\n",
      "<Symbol data>\n",
      "\n",
      "=== the symbolic program of net===\n",
      "<Symbol hybridsequential1_dense2_fwd>\n",
      "\n",
      "=== the according json definition===\n",
      "{\n",
      "  \"nodes\": [\n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"data\", \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense0_weight\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(256, 0)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense0_bias\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__init__\": \"zeros\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(256,)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"FullyConnected\", \n",
      "      \"name\": \"hybridsequential1_dense0_fwd\", \n",
      "      \"attr\": {\"num_hidden\": \"256\"}, \n",
      "      \"inputs\": [[0, 0, 0], [1, 0, 0], [2, 0, 0]]\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"Activation\", \n",
      "      \"name\": \"hybridsequential1_dense0_relu_fwd\", \n",
      "      \"attr\": {\"act_type\": \"relu\"}, \n",
      "      \"inputs\": [[3, 0, 0]]\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense1_weight\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(128, 0)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense1_bias\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__init__\": \"zeros\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(128,)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"FullyConnected\", \n",
      "      \"name\": \"hybridsequential1_dense1_fwd\", \n",
      "      \"attr\": {\"num_hidden\": \"128\"}, \n",
      "      \"inputs\": [[4, 0, 0], [5, 0, 0], [6, 0, 0]]\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"Activation\", \n",
      "      \"name\": \"hybridsequential1_dense1_relu_fwd\", \n",
      "      \"attr\": {\"act_type\": \"relu\"}, \n",
      "      \"inputs\": [[7, 0, 0]]\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense2_weight\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(2, 0)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"null\", \n",
      "      \"name\": \"hybridsequential1_dense2_bias\", \n",
      "      \"attr\": {\n",
      "        \"__dtype__\": \"0\", \n",
      "        \"__init__\": \"zeros\", \n",
      "        \"__lr_mult__\": \"1.0\", \n",
      "        \"__shape__\": \"(2,)\", \n",
      "        \"__wd_mult__\": \"1.0\"\n",
      "      }, \n",
      "      \"inputs\": []\n",
      "    }, \n",
      "    {\n",
      "      \"op\": \"FullyConnected\", \n",
      "      \"name\": \"hybridsequential1_dense2_fwd\", \n",
      "      \"attr\": {\"num_hidden\": \"2\"}, \n",
      "      \"inputs\": [[8, 0, 0], [9, 0, 0], [10, 0, 0]]\n",
      "    }\n",
      "  ], \n",
      "  \"arg_nodes\": [0, 1, 2, 5, 6, 9, 10], \n",
      "  \"node_row_ptr\": [\n",
      "    0, \n",
      "    1, \n",
      "    2, \n",
      "    3, \n",
      "    4, \n",
      "    5, \n",
      "    6, \n",
      "    7, \n",
      "    8, \n",
      "    9, \n",
      "    10, \n",
      "    11, \n",
      "    12\n",
      "  ], \n",
      "  \"heads\": [[11, 0, 0]], \n",
      "  \"attrs\": {\"mxnet_version\": [\"int\", 1001]}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from mxnet import sym\n",
    "x = sym.var('data')\n",
    "print('=== input data holder ===')\n",
    "print(x)\n",
    "\n",
    "y = net(x)\n",
    "print('\\n=== the symbolic program of net===')\n",
    "print(y)\n",
    "\n",
    "y_json = y.tojson()\n",
    "print('\\n=== the according json definition===')\n",
    "print(y_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can save both the program and parameters onto disk, so that it can be loaded later not only in Python, but in all other supported languages, such as C++, R, and Scala, as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.save('model.json')\n",
    "net.save_params('model.params')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HybridParallel\n",
    "\n",
    "Just like sequential composition of networks, we can also compose them in parallel. That is, if we want $x$ to be transformed by multiple networks we can simply add them in parallel within a HybridParallel block. More details on how to compose networks of networks will be described in a separate section.\n",
    "\n",
    "## HybridBlock\n",
    "\n",
    "Now let's dive deeper into how `hybridize` works. Remember that another way to construct a network is to define a subclass of `gluon.Block`, by which we can flexibly write the forward function. \n",
    "\n",
    "Unsurprisingly, there is a hybridized version `HybridBlock`. We implement the previous MLP as: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "\n",
    "class Net(gluon.HybridBlock):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Net, self).__init__(**kwargs)\n",
    "        with self.name_scope():\n",
    "            self.fc1 = nn.Dense(256)\n",
    "            self.fc2 = nn.Dense(128)\n",
    "            self.fc3 = nn.Dense(2)\n",
    "\n",
    "    def hybrid_forward(self, F, x):\n",
    "        # F is a function space that depends on the type of x\n",
    "        # If x's type is NDArray, then F will be mxnet.nd\n",
    "        # If x's type is Symbol, then F will be mxnet.sym\n",
    "        print('type(x): {}, F: {}'.format(\n",
    "                type(x).__name__, F.__name__))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we feed data into the network, we can see that `hybrid_forward` is called twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1st forward ===\n",
      "type(x): NDArray, F: mxnet.ndarray\n",
      "=== 2nd forward ===\n",
      "type(x): NDArray, F: mxnet.ndarray\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net.collect_params().initialize()\n",
    "x = nd.random_normal(shape=(1, 512))\n",
    "print('=== 1st forward ===')\n",
    "y = net(x)\n",
    "print('=== 2nd forward ===')\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run it again after hybridizing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1st forward ===\n",
      "type(x): Symbol, F: mxnet.symbol\n",
      "=== 2nd forward ===\n"
     ]
    }
   ],
   "source": [
    "net.hybridize()\n",
    "print('=== 1st forward ===')\n",
    "y = net(x)\n",
    "print('=== 2nd forward ===')\n",
    "y = net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It differs from the previous execution in two aspects:\n",
    "\n",
    "1. the input data type now is `Symbol` even when we fed a `NDArray` into    `net`. `gluon`, because it implicitly constructed a symbolic data placeholder.\n",
    "2. `hybrid_forward` is called once at the first time we run `net(x)`. It is because `gluon` will construct the symbolic program on the first forward, and then keep it for reuse later.\n",
    "\n",
    "One main reason that the network is faster after hybridizing is because we don't need to repeatedly invoke the Python forward function, while keeping all computations within the highly efficient C++ backend engine.\n",
    "\n",
    "But the potential drawback is the loss of flexibility to write the forward function. In other ways, inserting `print` for debugging or control logic such as `if` and `for` into the forward function is not possible now.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Through `HybridSequental` and `HybridBlock`, we can convert an imperative program into a symbolic program by calling `hybridize`. "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "display_name": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "name": ""
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
